{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralODE_habr_full_dynamics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGjwmHyUkSav"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.color_palette(\"bright\")\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch.nn  import functional as F \n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ode_solve(z0, t0, t1, f):\n",
        "    \"\"\"\n",
        "    Простейший метод эволюции ОДУ - метод Эйлера\n",
        "    \"\"\"\n",
        "    h_max = 0.05\n",
        "    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n",
        "\n",
        "    h = (t1 - t0)/n_steps\n",
        "    t = t0\n",
        "    z = z0\n",
        "    \"\"\"\n",
        "    for i_step in range(n_steps):\n",
        "        z = z + h * f(z, t)\n",
        "        t = t + h\n",
        "    return z\n",
        "    \"\"\"\n",
        "    \n",
        "    for i_step in range(n_steps):\n",
        "        k1 = f ( z, t )\n",
        "        k2 = f( z + k1 * h / 2, t + h/2 )\n",
        "        k3 = f( z + k2 * h / 2, t + h/2 )\n",
        "        k4 = f( z + k3 * h , t + h )\n",
        "        z = z + h * ( k1 + 2*k2 + 2*k3 + k4 ) / 6\n",
        "        t = t + h\n",
        "    \n",
        "    return z    "
      ],
      "metadata": {
        "id": "LIN7MiFUkyL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEF(nn.Module):\n",
        "    def forward_with_grad(self, z, t, grad_outputs):\n",
        "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
        "        batch_size = z.shape[0]\n",
        "\n",
        "        out = self.forward(z, t)\n",
        "\n",
        "        a = grad_outputs\n",
        "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
        "            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n",
        "            allow_unused=True, retain_graph=True\n",
        "        )\n",
        "        # метод grad автоматически суммирует градие*н*ты для всех элементов батча, надо expand их обратно \n",
        "        if adfdp is not None:\n",
        "            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0)\n",
        "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
        "        if adfdt is not None:\n",
        "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
        "        return out, adfdz, adfdt, adfdp\n",
        "\n",
        "    def flatten_parameters(self):\n",
        "        p_shapes = []\n",
        "        flat_parameters = []\n",
        "        for p in self.parameters():\n",
        "            p_shapes.append(p.size())\n",
        "            flat_parameters.append(p.flatten())\n",
        "        return torch.cat(flat_parameters)"
      ],
      "metadata": {
        "id": "R4GDDfePk0rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEAdjoint(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, z0, t, flat_parameters, func):\n",
        "        assert isinstance(func, ODEF)\n",
        "        bs, *z_shape = z0.size()\n",
        "        time_len = t.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
        "            z[0] = z0\n",
        "            for i_t in range(time_len - 1):\n",
        "                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n",
        "                z[i_t+1] = z0\n",
        "\n",
        "        ctx.func = func\n",
        "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
        "        return z\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, dLdz):\n",
        "        \"\"\"\n",
        "        dLdz shape: time_len, batch_size, *z_shape\n",
        "        \"\"\"\n",
        "        func = ctx.func\n",
        "        t, z, flat_parameters = ctx.saved_tensors\n",
        "        time_len, bs, *z_shape = z.size()\n",
        "        n_dim = np.prod(z_shape)\n",
        "        n_params = flat_parameters.size(0)\n",
        "\n",
        "        # Динамика аугментированной системы, которую надо эволюционировать обратно во времени\n",
        "        def augmented_dynamics(aug_z_i, t_i):\n",
        "            \"\"\"\n",
        "            Тензоры здесь - это срезы по времени\n",
        "            t_i - тензор с размерами: bs, 1\n",
        "            aug_z_i - тензор с размерами: bs, n_dim*2 + n_params + 1\n",
        "            \"\"\"\n",
        "            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # игнорируем параметры и время\n",
        "\n",
        "            # Unflatten z and a\n",
        "            z_i = z_i.view(bs, *z_shape)\n",
        "            a = a.view(bs, *z_shape)\n",
        "            with torch.set_grad_enabled(True):\n",
        "                t_i = t_i.detach().requires_grad_(True)\n",
        "                z_i = z_i.detach().requires_grad_(True)\n",
        "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n",
        "                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n",
        "                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n",
        "                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
        "\n",
        "            # Flatten f and adfdz\n",
        "            func_eval = func_eval.view(bs, n_dim)\n",
        "            adfdz = adfdz.view(bs, n_dim) \n",
        "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
        "\n",
        "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz для удобства\n",
        "        with torch.no_grad():\n",
        "            ## Создадим плейсхолдеры для возвращаемых градиентов\n",
        "            # Распространенные назад сопряженные состояния, которые надо поправить градиентами от наблюдений\n",
        "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
        "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
        "            # В отличие от z и p, нужно вернуть градиенты для всех моментов времени\n",
        "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
        "\n",
        "            for i_t in range(time_len-1, 0, -1):\n",
        "                z_i = z[i_t]\n",
        "                t_i = t[i_t]\n",
        "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
        "\n",
        "                # Рассчитаем прямые градиенты от наблюдений\n",
        "                dLdz_i = dLdz[i_t]\n",
        "                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
        "\n",
        "                # Подправим ими сопряженные состояния\n",
        "                adj_z += dLdz_i\n",
        "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
        "\n",
        "                # Упакуем аугментированные переменные в вектор\n",
        "                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n",
        "\n",
        "                # Решим (эволюционируем) аугментированную систему назад во времени\n",
        "                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n",
        "\n",
        "                # Распакуем переменные обратно из решенной системы\n",
        "                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n",
        "                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n",
        "                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n",
        "\n",
        "                del aug_z, aug_ans\n",
        "\n",
        "            ## Подправим сопряженное состояние в нулевой момент времени прямыми градиентами\n",
        "            # Вычислим прямые градиенты\n",
        "            dLdz_0 = dLdz[0]\n",
        "            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n",
        "\n",
        "            # Подправим\n",
        "            adj_z += dLdz_0\n",
        "            adj_t[0] = adj_t[0] - dLdt_0\n",
        "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None"
      ],
      "metadata": {
        "id": "9yuf__qDk3Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralODE(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super(NeuralODE, self).__init__()\n",
        "        assert isinstance(func, ODEF)\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, z0, t=Tensor([0., 1.]), return_whole_sequence=False):\n",
        "        t = t.to(z0)\n",
        "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
        "        if return_whole_sequence:\n",
        "            return z\n",
        "        else:\n",
        "            return z[-1]"
      ],
      "metadata": {
        "id": "cwj1yPRuk5-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearODEF(ODEF):\n",
        "    def __init__(self, W):\n",
        "        super(LinearODEF, self).__init__()\n",
        "        self.lin = nn.Linear(2, 2, bias=False)\n",
        "        self.lin.weight = nn.Parameter(W)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        return self.lin(x)"
      ],
      "metadata": {
        "id": "DUj8dAykk8yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpiralFunctionExample(LinearODEF):\n",
        "    def __init__(self):\n",
        "        super(SpiralFunctionExample, self).__init__(Tensor([[-0.1, -1.], [1., -0.1]]))"
      ],
      "metadata": {
        "id": "TOuDourdlF7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomLinearODEF(LinearODEF):\n",
        "    def __init__(self):\n",
        "        super(RandomLinearODEF, self).__init__(torch.randn(2, 2)/2.)"
      ],
      "metadata": {
        "id": "xJoRpU-8lH5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestODEF(ODEF):\n",
        "    def __init__(self, A, B, x0):\n",
        "        super(TestODEF, self).__init__()\n",
        "        self.A = nn.Linear(2, 2, bias=False)\n",
        "        self.A.weight = nn.Parameter(A)\n",
        "        self.B = nn.Linear(2, 2, bias=False)\n",
        "        self.B.weight = nn.Parameter(B)\n",
        "        self.x0 = nn.Parameter(x0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        xTx0 = torch.sum(x*self.x0, dim=1)\n",
        "        dxdt = torch.sigmoid(xTx0) * self.A(x - self.x0) + torch.sigmoid(-xTx0) * self.B(x + self.x0)\n",
        "        return dxdt"
      ],
      "metadata": {
        "id": "antBAyzwlJei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NNODEF(ODEF):\n",
        "    def __init__(self, in_dim, hid_dim, time_invariant=False):\n",
        "        super(NNODEF, self).__init__()\n",
        "        self.time_invariant = time_invariant\n",
        "\n",
        "        if time_invariant:\n",
        "            self.lin1 = nn.Linear(in_dim, hid_dim)\n",
        "        else:\n",
        "            self.lin1 = nn.Linear(in_dim+1, hid_dim)\n",
        "        self.lin2 = nn.Linear(hid_dim, hid_dim)\n",
        "        self.lin3 = nn.Linear(hid_dim, in_dim)\n",
        "        self.elu = nn.ELU(inplace=True)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        if not self.time_invariant:\n",
        "            x = torch.cat((x, t), dim=-1)\n",
        "\n",
        "        h = self.elu(self.lin1(x))\n",
        "        h = self.elu(self.lin2(h))\n",
        "        out = self.lin3(h)\n",
        "        return out"
      ],
      "metadata": {
        "id": "_Y0-TAsPlLdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_np(x):\n",
        "    return x.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "f9UE2xFMlNN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "images_dir = '/content/gdrive/My Drive/OUTPUT_collab'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkruE-kd1M3f",
        "outputId": "c85f7837-2fff-4514-c39c-ec0f9929359b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_trajectories(obs=None, times=None, trajs=None, save=None, figsize=(16, 8)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    if obs is not None:\n",
        "        if times is None:\n",
        "            times = [None] * len(obs)\n",
        "        for o, t in zip(obs, times):\n",
        "            o, t = to_np(o), to_np(t)\n",
        "            for b_i in range(o.shape[1]):\n",
        "                plt.scatter(o[:, b_i, 0], o[:, b_i, 1], c=t[:, b_i, 0], cmap=cm.plasma)\n",
        "\n",
        "    if trajs is not None: \n",
        "        for z in trajs:\n",
        "            z = to_np(z)\n",
        "            plt.plot(z[:, 0, 0], z[:, 0, 1], lw=1.5)      \n",
        "        if save is not None:\n",
        "            plt.savefig(save)\n",
        "            #plt.savefig(f\"{images_dir}/abc.png\")\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "F0_pnJbilO-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conduct_experiment(ode_true, ode_trained, n_steps, name, plot_freq=10):\n",
        "    # Create data\n",
        "    z0 = Variable(torch.Tensor([[0.6, 0.3]]))\n",
        "\n",
        "    t_max = 6.29*5\n",
        "    n_points = 200\n",
        "\n",
        "    index_np = np.arange(0, n_points, 1, dtype=np.int)\n",
        "    index_np = np.hstack([index_np[:, None]])\n",
        "    times_np = np.linspace(0, t_max, num=n_points)\n",
        "    times_np = np.hstack([times_np[:, None]])\n",
        "\n",
        "    times = torch.from_numpy(times_np[:, :, None]).to(z0)\n",
        "    obs = ode_true(z0, times, return_whole_sequence=True).detach()\n",
        "    obs = obs + torch.randn_like(obs) * 0.01\n",
        "\n",
        "    # Get trajectory of random timespan \n",
        "    min_delta_time = 1.0\n",
        "    max_delta_time = 5.0\n",
        "    max_points_num = 32\n",
        "    def create_batch():\n",
        "        t0 = np.random.uniform(0, t_max - max_delta_time)\n",
        "        t1 = t0 + np.random.uniform(min_delta_time, max_delta_time)\n",
        "\n",
        "        idx = sorted(np.random.permutation(index_np[(times_np > t0) & (times_np < t1)])[:max_points_num])\n",
        "\n",
        "        obs_ = obs[idx]\n",
        "        ts_ = times[idx]\n",
        "        return obs_, ts_\n",
        "\n",
        "    # Train Neural ODE\n",
        "    optimizer = torch.optim.Adam(ode_trained.parameters(), lr=0.01)\n",
        "    for i in range(n_steps):\n",
        "        obs_, ts_ = create_batch()\n",
        "\n",
        "        z_ = ode_trained(obs_[0], ts_, return_whole_sequence=True)\n",
        "        loss = F.mse_loss(z_, obs_.detach())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % plot_freq == 0:\n",
        "            z_p = ode_trained(z0, times, return_whole_sequence=True)\n",
        "\n",
        "            plot_trajectories(obs=[obs], times=[times], trajs=[z_p], save= f\"{images_dir}/{name}/{i}.png\")\n",
        "            clear_output(wait=True)"
      ],
      "metadata": {
        "id": "KMYG2HN0lQvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ode_true = NeuralODE(SpiralFunctionExample())\n",
        "ode_trained = NeuralODE(RandomLinearODEF())"
      ],
      "metadata": {
        "id": "11fbVzEmlVFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conduct_experiment(ode_true, ode_trained, 1000, \"NeuralODE_images_linear\")"
      ],
      "metadata": {
        "id": "ZO9xl0C-lWth",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "65c0187b-57a6-4853-8d78-28ae142f8d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-f9270a4a699b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconduct_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mode_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mode_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NeuralODE_images_linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-2d5c8c38bc33>\u001b[0m in \u001b[0;36mconduct_experiment\u001b[0;34m(ode_true, ode_trained, n_steps, name, plot_freq)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m                                \"of them.\")\n\u001b[1;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-ea8309897a19>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, dLdz)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# Решим (эволюционируем) аугментированную систему назад во времени\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0maug_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mode_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_t\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_dynamics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# Распакуем переменные обратно из решенной системы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-63b96f37d3a7>\u001b[0m in \u001b[0;36mode_solve\u001b[0;34m(z0, t0, t1, f)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mk3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mk4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk4\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-ea8309897a19>\u001b[0m in \u001b[0;36maugmented_dynamics\u001b[0;34m(aug_z_i, t_i)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mt_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mfunc_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madfdz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madfdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madfdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_with_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bs, *z_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0madfdz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfdz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madfdz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mz_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0madfdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madfdp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-eb26d80caa4a>\u001b[0m in \u001b[0;36mforward_with_grad\u001b[0;34m(self, z, t, grad_outputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# метод grad автоматически суммирует градие*н*ты для всех элементов батча, надо expand их обратно\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madfdp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0madfdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp_grad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madfdp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0madfdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madfdt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = TestODEF(Tensor([[-0.1, -0.5], [0.5, -0.1]]), Tensor([[0.2, 1.], [-1, 0.2]]), Tensor([[-1., 0.]]))\n",
        "ode_true = NeuralODE(func)\n",
        "\n",
        "func = NNODEF(2, 16, time_invariant=True)\n",
        "ode_trained = NeuralODE(func)"
      ],
      "metadata": {
        "id": "Un1B5NUE5vfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conduct_experiment(ode_true, ode_trained, 3000, \"Neural_ODE_no_linear\", plot_freq=30)"
      ],
      "metadata": {
        "id": "gjqqzreb5yrw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "8d1d75b3-f8a7-44f9-9752-fa7a8b7615ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-c7191fb4c9f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconduct_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mode_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mode_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Neural_ODE_no_linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-2d5c8c38bc33>\u001b[0m in \u001b[0;36mconduct_experiment\u001b[0;34m(ode_true, ode_trained, n_steps, name, plot_freq)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m                                \"of them.\")\n\u001b[1;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-ea8309897a19>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, dLdz)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# Решим (эволюционируем) аугментированную систему назад во времени\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0maug_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mode_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_t\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_dynamics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# Распакуем переменные обратно из решенной системы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-63b96f37d3a7>\u001b[0m in \u001b[0;36mode_solve\u001b[0;34m(z0, t0, t1, f)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mk3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mk4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk4\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-ea8309897a19>\u001b[0m in \u001b[0;36maugmented_dynamics\u001b[0;34m(aug_z_i, t_i)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mt_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mfunc_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madfdz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madfdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madfdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_with_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bs, *z_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0madfdz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfdz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madfdz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mz_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0madfdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madfdp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-eb26d80caa4a>\u001b[0m in \u001b[0;36mforward_with_grad\u001b[0;34m(self, z, t, grad_outputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         adfdz, adfdt, *adfdp = torch.autograd.grad(\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         )\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# метод grad автоматически суммирует градие*н*ты для всех элементов батча, надо expand их обратно\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    257\u001b[0m                       \"parts of the graph, please use torch.autograd.backward.\")\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_grads_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_tensor_or_tensors_to_tuple\u001b[0;34m(tensors, length)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_TensorOrTensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_OptionalTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}